

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Getting Started &mdash; TheCannon 0.3.4 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="TheCannon 0.3.4 documentation" href="index.html"/>
        <link rel="next" title="Reference/API" href="api.html"/>
        <link rel="prev" title="Requirements for Input" href="input_requirements.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="index.html" class="icon icon-home"> TheCannon
        

        
        </a>

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="input_requirements.html">Requirements for Input</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Reference/API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-TheCannon.apogee">APOGEE Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#dataset">Dataset</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api.html#model">Model</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">TheCannon</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Getting Started</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/getting_started.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">Â¶</a></h1>
<p><tt class="docutils literal"><span class="pre">TheCannon</span></tt> can be installed using <tt class="docutils literal"><span class="pre">pip</span></tt>:</p>
<blockquote>
<div>$ pip install TheCannon</div></blockquote>
<p>Here is an overview of the basic workflow using a simple illustration
with APOGEE DR10 data in which the test set is identical to the training set.
To run this example, download the file <tt class="docutils literal"><span class="pre">example_DR10.tar.gz</span></tt> by clicking
<a class="reference download internal" href="_downloads/example_DR10.tar.gz"><tt class="xref download docutils literal"><span class="pre">here</span></tt></a>
and unzip it using the command</p>
<blockquote>
<div>$ tar -zxvf example_DR10.tar.gz</div></blockquote>
<p>This file contains the following:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">Data</span></tt>: a folder with .fits data files</li>
<li><tt class="docutils literal"><span class="pre">reference_labels.csv</span></tt>: a table with reference label values for the training step</li>
<li><tt class="docutils literal"><span class="pre">Results</span></tt>: a folder with all of the diagnostic output plots that <tt class="docutils literal"><span class="pre">TheCannon</span></tt> produces in this example</li>
</ul>
<p>Before the data can be run through <tt class="docutils literal"><span class="pre">TheCannon</span></tt>, it must be prepared
according to the specifications laid out in the &#8220;Requirements for Input&#8221;
section. One of the requirements is for data to be continuum normalized
in a SNR-independent way. <tt class="docutils literal"><span class="pre">TheCannon</span></tt> does have built-in
options for continuum normalizing spectra, and we illustrate that here.</p>
<p>Here are the steps for reading in the data. In practice, the user would
write his own code; for this example, we provide the module <tt class="docutils literal"><span class="pre">apogee.py</span></tt>.
The procedure for reading in spectra and training labels of course depends on
the survey, the file type, etc, and it is up to the user to package this
all appropriately before feeding it into <tt class="docutils literal"><span class="pre">TheCannon</span></tt>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">TheCannon</span> <span class="kn">import</span> <span class="n">apogee</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tr_ID</span><span class="p">,</span> <span class="n">wl</span><span class="p">,</span> <span class="n">tr_flux</span><span class="p">,</span> <span class="n">tr_ivar</span> <span class="o">=</span> <span class="n">apogee</span><span class="o">.</span><span class="n">load_spectra</span><span class="p">(</span><span class="s">&quot;example_DR10/Data&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">all_labels</span> <span class="o">=</span> <span class="n">apogee</span><span class="o">.</span><span class="n">load_labels</span><span class="p">(</span><span class="s">&quot;example_DR10/reference_labels.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>There should be 548 spectra with 8575 pixels each.</p>
<p>For simplicity, we set the test set is set as equal to the training set, so that
<tt class="docutils literal"><span class="pre">TheCannon</span></tt> is simply re-determining labels for the reference objects. In
practice, the test IDs, fluxes, and inverse variances would be read in
separately.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">test_ID</span> <span class="o">=</span> <span class="n">tr_ID</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_flux</span> <span class="o">=</span> <span class="n">tr_flux</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_ivar</span> <span class="o">=</span> <span class="n">tr_ivar</span>
</pre></div>
</div>
<p>The <tt class="docutils literal"><span class="pre">reference_label.csv</span></tt> file contains more labels than we want to use;
in this example, we only want effective temperature, metallicity, and surface
gravity. The output from the <tt class="docutils literal"><span class="pre">apogee.load_labels</span></tt> step shows which column
corresponds to which label, so we select them as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">teff</span> <span class="o">=</span> <span class="n">all_labels</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logg</span> <span class="o">=</span> <span class="n">all_labels</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mh</span> <span class="o">=</span> <span class="n">all_labels</span><span class="p">[:,</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
<p>and then repackage them to suit the requirements in &#8220;Requirements for Input:&#8221;</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tr_label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">teff</span><span class="p">,</span> <span class="n">logg</span><span class="p">,</span> <span class="n">mh</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
<p>Now, all the input data has been packaged properly, and we can begin running
<tt class="docutils literal"><span class="pre">TheCannon.</span></tt></p>
<p>The first step is to initialize a <tt class="docutils literal"><span class="pre">Dataset</span></tt> object:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">TheCannon</span> <span class="kn">import</span> <span class="n">dataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span><span class="n">wl</span><span class="p">,</span> <span class="n">tr_ID</span><span class="p">,</span> <span class="n">tr_flux</span><span class="p">,</span> <span class="n">tr_ivar</span><span class="p">,</span> <span class="n">tr_label</span><span class="p">,</span> <span class="n">test_ID</span><span class="p">,</span> <span class="n">test_flux</span><span class="p">,</span> <span class="n">test_ivar</span><span class="p">)</span>
</pre></div>
</div>
<p><tt class="docutils literal"><span class="pre">TheCannon</span></tt> has a number of optional diagnostic plots built-in, to help the
user visualize the results. Some of these plots require knowing the names
of the labels. If the user wants to produce these diagnostic plots, he or
she must specify the label names in LaTeX format:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">set_label_names</span><span class="p">([</span><span class="s">&#39;T_{eff}&#39;</span><span class="p">,</span> <span class="s">&#39;\log g&#39;</span><span class="p">,</span> <span class="s">&#39;[Fe/H]&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>At this stage, two diagnotic plots can already be produced,
one with the distribution
of SNR in the training and test set (in practice, the training set
should consist of higher SNR spectra than the test set)
and the other using <tt class="docutils literal"><span class="pre">triangle.py</span></tt> to plot
every label&#8217;s set of training values against every other.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">diagnostics_SNR</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">diagnostics_ref_labels</span><span class="p">()</span>
</pre></div>
</div>
<p>The output is saved to the directory that <tt class="docutils literal"><span class="pre">TheCannon</span></tt> is being run in.
The first should be called <tt class="docutils literal"><span class="pre">SNRdist.png</span></tt> and look as follows:</p>
<img alt="_images/SNRdist.png" src="_images/SNRdist.png" />
<p>The second should be called <tt class="docutils literal"><span class="pre">ref_labels_triangle.png</span></tt> and look as follows:</p>
<img alt="_images/ref_labels_triangle.png" src="_images/ref_labels_triangle.png" />
<p>Again, <tt class="docutils literal"><span class="pre">TheCannon</span></tt> requires incoming spectra to be continuum normalized
in a way that is independent of signal to noise. If the data does not satisfy
this criteria already, the user can use the continuum identification and
normalization functions built into <tt class="docutils literal"><span class="pre">TheCannon</span></tt>.</p>
<p>First, continuum pixels are identified from a pseudo-continuum normalized
version of the training set spectra. Pseudo-continuum normalization is
performed using a running quantile. In this case, the
window size for calculating the median is set to 50 Angstroms and the quantile
level is set to 90%. APOGEE spectra come in three chunks, and we want to
perform continuum normalization for each chunk separately. For <tt class="docutils literal"><span class="pre">TheCannon</span></tt>
to treat spectra in chunks, the <tt class="docutils literal"><span class="pre">ranges</span></tt> attribute must be set:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">ranges</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">371</span><span class="p">,</span><span class="mi">3192</span><span class="p">],</span> <span class="p">[</span><span class="mi">3697</span><span class="p">,</span><span class="mi">5997</span><span class="p">],</span> <span class="p">[</span><span class="mi">6461</span><span class="p">,</span><span class="mi">8255</span><span class="p">]]</span>
</pre></div>
</div>
<p>Even if a spectral dataset do not consist of chunks separated by gaps, one can
imagine other reasons for wanting to treat a spectrum as though it had gaps:
for example, if different regions of a spectrum behave very differently, it
might be sensible to treat each of them separately in continuum normalization.
The user should make sure to examine the results of continuum normalization,
for example plotting fifty sample continuum fits and continuum normalized
spectra.</p>
<p>Pseudo continuum normalization can then be performed as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">pseudo_tr_flux</span><span class="p">,</span> <span class="n">pseudo_tr_ivar</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">continuum_normalize_training_q</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span><span class="n">q</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">delta_lambda</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
<p>Once the pseudo continuum has been calculated, a continuum mask is created:
True values correspond to pixels that are continuum, False to those that are
not. &#8220;True&#8221; continuum pixels are identified using a median and variance flux
cut across the training objects: in other words, continuum pixels are those
that consistently have values close to 1 in all of the training spectra. The
user specifies what fraction of pixels to identify as continuum, and the
flux and variance cuts are determined appropriately. If the <tt class="docutils literal"><span class="pre">dataset.ranges</span></tt>
attribute is set, then continuum pixels are identified separately for each
region (in this case, three regions). This enables the user to control how
evenly spread the pixels are.</p>
<p>In this case, we choose 7% of the pixels in the spectrum as continuum, but the
best value should be determined through experimentation.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">contmask</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">make_contmask</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span><span class="n">pseudo_tr_flux</span><span class="p">,</span> <span class="n">pseudo_tr_ivar</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.07</span><span class="p">)</span>
</pre></div>
</div>
<p>At this stage, the user should plot spectra overlaid with the identified
continuum pixels to ensure that they look reasonable and that they roughly
evenly cover the spectrum. Large gaps in continuum pixels could result in
poor continuum normalization in those regions. If the continuum pixels
do not look evenly sampled enough, the range can be changed and the process
repeated. For this example, we change it as foollows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">ranges</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">371</span><span class="p">,</span><span class="mi">3192</span><span class="p">],</span> <span class="p">[</span><span class="mi">3697</span><span class="p">,</span><span class="mi">5500</span><span class="p">],</span> <span class="p">[</span><span class="mi">5500</span><span class="p">,</span><span class="mi">5997</span><span class="p">],</span> <span class="p">[</span><span class="mi">6461</span><span class="p">,</span><span class="mi">8255</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contmask</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">make_contmask</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span><span class="n">pseudo_tr_flux</span><span class="p">,</span> <span class="n">pseudo_tr_ivar</span><span class="p">,</span> <span class="n">frac</span><span class="o">=</span><span class="mf">0.07</span><span class="p">)</span>
</pre></div>
</div>
<p>Once a satisfactory set of continuum pixels has been identified, the dataset&#8217;s
continuum mask attribute is set as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">set_continuum</span><span class="p">(</span><span class="n">contmask</span><span class="p">)</span>
</pre></div>
</div>
<p>Once the dataset has a continuum mask, the continuum is fit for using either
a sinusoid or chebyshev function. In this case, we use a sinusoid; the user
can specify the desired order. Again, this is 3 for this simple illustration,
but should be determined through experimentation.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">cont</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">fit_continuum</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s">&quot;sinusoid&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Once a satisfactory continuum has been fit, the normalized training and test
spectra can be calculated:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">norm_tr_flux</span><span class="p">,</span> <span class="n">norm_tr_ivar</span><span class="p">,</span> <span class="n">norm_test_flux</span><span class="p">,</span> <span class="n">norm_test_ivar</span> <span class="o">=</span> \
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">continuum_normalize</span><span class="p">(</span><span class="n">cont</span><span class="p">)</span>
</pre></div>
</div>
<p>If these normalized spectra look acceptable, then they can be set:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">tr_flux</span> <span class="o">=</span> <span class="n">norm_tr_flux</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">tr_ivar</span> <span class="o">=</span> <span class="n">norm_tr_ivar</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">test_flux</span> <span class="o">=</span> <span class="n">norm_test_flux</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">test_ivar</span> <span class="o">=</span> <span class="n">norm_test_ivar</span>
</pre></div>
</div>
<p>Now, the data munging is over and we&#8217;re ready to run <tt class="docutils literal"><span class="pre">TheCannon</span></tt>!</p>
<p>For the training step (fitting for the spectral model) all the user needs to
specify is the desired polynomial order of the spectral model.
In this case, we use a quadratic model: order = 2</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">TheCannon</span> <span class="kn">import</span> <span class="n">model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">CannonModel</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>
</div>
<p>equivalently,</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>At this stage, more optional diagnostic plots can be produced to examine
the spectral model:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">diagnostics</span><span class="p">()</span>
</pre></div>
</div>
<p>The first is a series of plots showing the full baseline (first-order) model
spectrum with continuum pixels overplotted.</p>
<img alt="_images/contpix.gif" src="_images/contpix.gif" />
<p>The second is a plot of the leading coefficients and scatter of the model
as a function of wavelength</p>
<img alt="_images/leading_coeffs.png" src="_images/leading_coeffs.png" />
<p>The third is a histogram of the reduced chi squareds of the model fit.</p>
<img alt="_images/modelfit_chisqs.png" src="_images/modelfit_chisqs.png" />
<p>If the model fitting worked, then we can proceed to the test step. This
command automatically updates the dataset with the fitted-for test labels,
and returned the corresponding covariance matrix.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">label_errs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer_labels</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
<p>A set of diagnostic output:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">diagnostics_test_step_flagstars</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">diagnostics_survey_labels</span><span class="p">()</span>
</pre></div>
</div>
<p>The first generates one text file for each label, called <tt class="docutils literal"><span class="pre">flagged_stars.txt</span></tt>.
The second generates a triangle plot of the survey (Cannon) labels,
shown below.</p>
<img alt="_images/survey_labels_triangle.png" src="_images/survey_labels_triangle.png" />
<p>If the test set is simply equivalent to the training set,
as in this example, then one final diagnostic plot can be produced:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dataset</span><span class="o">.</span><span class="n">diagnostics_1to1</span><span class="p">()</span>
</pre></div>
</div>
<img alt="1to1_label_0.png" src="1to1_label_0.png" />
<img alt="1to1_label_1.png" src="1to1_label_1.png" />
<img alt="1to1_label_2.png" src="1to1_label_2.png" />
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="api.html" class="btn btn-neutral float-right" title="Reference/API" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="input_requirements.html" class="btn btn-neutral" title="Requirements for Input" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Anna Ho.
    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.4',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>